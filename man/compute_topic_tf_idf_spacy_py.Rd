% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_topic_tf_idf_spacy_py.R
\name{compute_topic_tf_idf_spacy_py}
\alias{compute_topic_tf_idf_spacy_py}
\title{Compute topic-level term scores using spaCy (Python)}
\usage{
compute_topic_tf_idf_spacy_py(
  data,
  doc_col = "doc_id",
  topic_col = "cluster",
  text_col = "text",
  spacy_model = "en_core_web_sm",
  pos_keep = c("NOUN", "PROPN"),
  min_char = 3L,
  min_term_freq = 2L,
  top_n = 10L,
  stopwords = NULL,
  use_tfidf = TRUE,
  exclude_topics = NULL,
  min_ngram = 1L,
  max_ngram = 1L,
  ngram_sep = " "
)
}
\arguments{
\item{data}{A data frame (or tibble) containing at least the document
identifier, topic/cluster label, and text columns.}

\item{doc_col}{A string giving the name of the column in \code{data}
that contains unique document identifiers. Default is \code{"doc_id"}.}

\item{topic_col}{A string giving the name of the column in \code{data}
that contains the topic or cluster assignment for each document.
Default is \code{"cluster"}.}

\item{text_col}{A string giving the name of the column in \code{data}
that contains the raw text to be analysed. Default is \code{"text"}.}

\item{spacy_model}{A string with the name of the spaCy model to use,
e.g. \code{"en_core_web_sm"}. The model must be installed and available
in the active Python environment. Default is \code{"en_core_web_sm"}.}

\item{pos_keep}{A character vector of coarse-grained POS tags (as used
by spaCy, e.g. \code{"NOUN"}, \code{"PROPN"}) that should be retained
when computing term statistics. Tokens with other POS tags are discarded.
Default is \code{c("NOUN", "PROPN")}.}

\item{min_char}{Integer; minimum number of characters a token must have
to be kept. Shorter tokens are discarded. Default is \code{3L}.}

\item{min_term_freq}{Integer; minimum term frequency (across all
documents/topics) required for a term to be kept. Terms that occur fewer
times than this threshold are removed. Default is \code{2L}.}

\item{top_n}{Integer; number of top-ranking terms to return per topic
after scoring (e.g. by TF–IDF). Default is \code{10L}.}

\item{stopwords}{Optional character vector of stopwords to remove
before computing term statistics. If \code{NULL} (default), no
additional stopwords are removed apart from those filtered by
POS/length/frequency.}

\item{use_tfidf}{Logical; if \code{TRUE} (default), compute TF–IDF
scores per topic. If \code{FALSE}, only term frequencies are computed
and returned.}

\item{exclude_topics}{Optional vector of topic labels (values found in
\code{topic_col}) that should be excluded from the computation. If
\code{NULL} (default), all topics are included.}

\item{min_ngram}{Integer; minimum n-gram size to construct from the
token sequence. Default is \code{1L} (unigrams).}

\item{max_ngram}{Integer; maximum n-gram size to construct from the
token sequence. Must be greater than or equal to \code{min_ngram}.
Default is \code{1L} (no n-grams beyond unigrams).}

\item{ngram_sep}{A single-character string used to join tokens when
forming n-grams. Default is a space (\code{" "}).}
}
\value{
A tibble or data frame with one row per (topic, term) combination
and at least the following columns:
\itemize{
\item \code{topic} (or the values from \code{topic_col})
\item \code{term} (unigrams or n-grams)
\item term frequency and, if requested, TF–IDF score
\item a rank or ordering within each topic (if implemented)
}
The exact column names may depend on the implementation.
}
\description{
This function takes a data frame with documents, their topic (cluster)
assignments, and raw text, and computes term statistics per topic using a
spaCy (Python) model. It tokenises the text, keeps only selected part-of-speech
tags (e.g. nouns and proper nouns), optionally builds n-grams, filters
short and infrequent terms, and computes term scores (TF or TF–IDF) per
topic. The output is a tidy data frame with the top terms for each topic.
}
\details{
Internally, this function relies on a Python spaCy pipeline (accessed
via \pkg{reticulate}) to perform tokenisation and POS-tagging. Make sure
that a suitable Python environment is available, spaCy is installed in
that environment, and the specified \code{spacy_model} has been downloaded.

The function aggregates terms at the topic level, filters them according
to the length and frequency thresholds, optionally constructs n-grams, and
then computes per-topic term scores. When \code{use_tfidf = TRUE}, a
TF–IDF-like weighting is used to highlight terms that are frequent within
a topic but relatively rare across other topics.
}
\examples{
\dontrun{
# Minimal example
library(tibble)

toy_data <- tibble::tibble(
  doc_id  = c("d1", "d2", "d3"),
  cluster = c(1, 1, 2),
  text    = c(
    "Solar energy systems and photovoltaic panels",
    "Photovoltaic modules for sustainable energy",
    "Wind turbines and offshore energy production"
  )
)

topic_terms <- compute_topic_tf_idf_spacy_py(
  data       = toy_data,
  doc_col    = "doc_id",
  topic_col  = "cluster",
  text_col   = "text",
  spacy_model = "en_core_web_sm",
  pos_keep    = c("NOUN", "PROPN"),
  min_ngram   = 1L,
  max_ngram   = 2L,
  top_n       = 5L
)
}
}
